# ===========================================
# NiveshAI Server Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values

# Server Configuration
PORT=3000

# ===========================================
# Groq API Configuration (REQUIRED)
# ===========================================
# Get your API key at: https://console.groq.com
GROQ_API_URL=https://api.groq.com/openai/v1/chat/completions
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_MAX_TOKENS=2000
GROQ_TIMEOUT_MS=60000

# ===========================================
# AWS S3 Configuration (OPTIONAL)
# ===========================================
# Required only if using S3 for file storage
# Leave empty to use local file storage
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your-bucket-name

# ===========================================
# Vector Database Configuration (OPTIONAL)
# ===========================================
# For production, configure Pinecone or OpenSearch
# Currently uses in-memory local vector store
# PINECONE_API_KEY=your_pinecone_api_key
# PINECONE_ENVIRONMENT=your_pinecone_environment
# PINECONE_INDEX_NAME=your_index_name

# ===========================================
# Embedding Service Configuration (OPTIONAL)
# ===========================================
# For production, use OpenAI or Cohere embeddings
# Currently uses local deterministic embeddings
# OPENAI_API_KEY=your_openai_api_key
# EMBEDDING_MODEL=text-embedding-3-small
